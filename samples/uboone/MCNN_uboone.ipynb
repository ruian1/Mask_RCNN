{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "particle2pdg={11:'eminus',-11:'eminus',13:'muon',-13:'muon',22:'gamma',211:'piminus',-211:'piminus',2212:'proton'}\n",
    "pdg2instance={'eminus':3,'gamma':4,'muon':6,'piminus':8,'proton':9}\n",
    "\n",
    "from larcv import larcv\n",
    "\n",
    "from MCNN_uboone import UbooneConfig\n",
    "class ShapesConfig(UbooneConfig):\n",
    "#     RPN_ANCHOR_RATIOS = [0.25, 0.5,  1,  2, 4]\n",
    "    RPN_ANCHOR_RATIOS = [0.5,  1,  2]\n",
    "config = ShapesConfig()\n",
    "config.display()\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n",
    "\n",
    "def getRGBfromI(RGBint):\n",
    "#     print RGBint\n",
    "    RGBint=int(RGBint)\n",
    "    blue =  RGBint & 255\n",
    "    green = (RGBint >> 8) & 255\n",
    "    red =   (RGBint >> 16) & 255\n",
    "    return red, green, blue\n",
    "\n",
    "from MCNN_uboone import UbooneDataset\n",
    "dataset_train = UbooneDataset(\"/scratch/ruian/training_data/no_pion.root\")\n",
    "# dataset_train = UbooneDataset(\"/scratch/ruian/training_data/track_par_val.root\")\n",
    "# dataset_train = UbooneDataset(\"/scratch/ruian/training_data/75_200_mul_2.root\")\n",
    "\n",
    "\n",
    "# dataset_val = UbooneDataset(\"/data/dayajun/toymodel/uboone/train_data/75_200.root\")\n",
    "# dataset_val.load_events(1, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "# dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train.load_events(100, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "print len(dataset_train.image_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dataset_train.class_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reload(modellib)\n",
    "# reload(visualize)\n",
    "# reload(utils)\n",
    "#Look at dataset_val\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(20,10))\n",
    "# fig, ax0 = plt.subplots(1,1,figsize=(10,10))\n",
    "# fig, ax1 = plt.subplots(1,1,figsize=(10,10))\n",
    "\n",
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "image_id=0\n",
    "# print 'image_id ',image_id\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_train, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "# print np.sum(original_image)\n",
    "    \n",
    "# log(\"original_image\", original_image)\n",
    "# log(\"image_meta\", image_meta)\n",
    "# log(\"gt_class_id\", str(gt_class_id))\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)\n",
    "# print np.sum(original_image)\n",
    "\n",
    "#     print '===========Detection==========='\n",
    "ax0.imshow(original_image[:,:,0], origin='lower')\n",
    "\n",
    "\n",
    "# ax0.set_ylim(512 + 10, -10)\n",
    "# ax0.set_xlim(-10, 512 + 10)\n",
    "\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8),ax=ax1)\n",
    "ax1.text(10,450,'image_id: %i'%image_id, color='w', fontsize=25)\n",
    "\n",
    "# print gt_bbox\n",
    "# print gt_class_id\n",
    "# print dataset_train.class_names \n",
    "boxes=dataset_train.load_bbox(image_id)\n",
    "\n",
    "# print gt_bbox\n",
    "print set(gt_mask.flatten())\n",
    "print gt_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "table=dataset_train.class_info\n",
    "x=40\n",
    "for x in range(x,x+20):\n",
    "    fig, (ax0,ax1) = plt.subplots(1,2,figsize=(20,10))\n",
    "    image_id=x\n",
    "    # print 'image_id ',image_id\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_train, inference_config, \n",
    "                               image_id, use_mini_mask=False)\n",
    "\n",
    "#     print gt_bbox\n",
    "#     print gt_class_id\n",
    "#     print dataset_train.class_names \n",
    "    \n",
    "    # print np.sum(original_imag\n",
    "    ax0.imshow(original_image[:,:,0], origin='lower')\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8),ax=ax1)\n",
    "#     ax1.text(10,450,'image_id: %i'%image_id, color='w', fontsize=25)\n",
    "#     for i in xrange(len(gt_class_id)):\n",
    "#         ax1.text(10,410-i*30,'%ith pdg: %i'%(i,table[gt_class_id[i]]['name']), color='w', fontsize=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=b=np.array([1])\n",
    "b[0]=2\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b=np.array([1])\n",
    "a=b.copy()\n",
    "b[0]=2\n",
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test= np.array([1,2,3,4,5])\n",
    "# test[test==1]=0\n",
    "# test[test==2]=0\n",
    "print (test==1) + (test==2)\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = dataset_train.load_bbox(0)\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[:,:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=np.zeros((2,4,2))\n",
    "print test[0]\n",
    "# test[0]=np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print dataset_train.image_ids\n",
    "image_ids = np.random.choice(dataset_train.image_ids, 2)\n",
    "# image_ids=[0,1]\n",
    "# print image_ids\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "#     print 'image_id',image_id\n",
    "#     print image.shape\n",
    "#     print set(image.flatten())\n",
    "#     print np.sum(image)\n",
    "#     print mask.shape\n",
    "#     for i in xrange(mask.shape[-1]):\n",
    "#         print np.sum(mask[:,:,i]),\n",
    "#     print ' '\n",
    "    print class_ids\n",
    "    visualize.display_top_masks(image[:,:,0], mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create model in training mode\n",
    "# model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "#                           model_dir=MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Training Heads\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "#             epochs=1, \n",
    "#             layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Training ALl\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE / 10,\n",
    "#             epochs=2, \n",
    "#             layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weight\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "# model_path = model.find_last()\n",
    "model_path=\"/data/dayajun/sw/Mask_RCNN/logs/particles20181001T1620/mask_rcnn_particles_0200.h5\"\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "# plot_model(model.keras_model)\n",
    "print len(model.keras_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# reload(visualize)\n",
    "# reload(utils)\n",
    "#Look at dataset_val\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "image_id = random.choice(dataset_train.image_ids)\n",
    "image_id=6\n",
    "print 'image_id ',image_id\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_train, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "# print np.sum(original_image)\n",
    "    \n",
    "# log(\"original_image\", original_image)\n",
    "# log(\"image_meta\", image_meta)\n",
    "# log(\"gt_class_id\", gt_class_id)\n",
    "# log(\"gt_bbox\", gt_bbox)\n",
    "# log(\"gt_mask\", gt_mask)\n",
    "# print np.sum(original_image)\n",
    "\n",
    "#     print '===========Detection==========='\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8),ax=ax0)\n",
    "print np.sum(original_image)\n",
    "results = model.detect([original_image], verbose=0)\n",
    "print np.sum(original_image)\n",
    "\n",
    "r = results[0]\n",
    "#     print r['rois'].shape\n",
    "#     print r['masks'].shape\n",
    "#     print r['class_ids'].shape\n",
    "#     print np.sum(original_image)\n",
    "\n",
    "# print np.sum(r['masks'])\n",
    "\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_train.class_names, r['scores'], ax=ax1)\n",
    "\n",
    "# visualize.display_differences(original_image,gt_bbox, gt_class_id, gt_mask, r['rois'],\\\n",
    "#                               r['class_ids'],r['scores'],r['masks']\\\n",
    "#                              ,dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset = dataset_val\n",
    "for image_id in xrange(0,50):\n",
    "    fig, (ax0,ax1) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset, inference_config, \n",
    "                               image_id, use_mini_mask=False)\n",
    "\n",
    "#     log(\"original_image\", original_image)\n",
    "#     log(\"image_meta\", image_meta)\n",
    "#     log(\"gt_class_id\", gt_class_id)\n",
    "#     log(\"gt_bbox\", gt_bbox)\n",
    "#     log(\"gt_mask\", gt_mask)\n",
    "#     print np.sum(original_image)\n",
    "\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                                dataset.class_names, figsize=(8, 8),ax=ax0)\n",
    "\n",
    "    results = model.detect([original_image], verbose=0)\n",
    "    r = results[0]\n",
    "            \n",
    "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                dataset.class_names, r['scores'], ax=ax1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(1,1,figsize=(8,6))\n",
    "ax.plot([0,0],[1,10],'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=np.zeros(shape=[512,512,5])\n",
    "# print test.shape\n",
    "for i in range(5):\n",
    "    test[:,:,i].fill(i)\n",
    "np.delete(test, 1)\n",
    "new=np.zeros([512,512])\n",
    "new.fill(6)\n",
    "# print test[:,:]\n",
    "# print new\n",
    "\n",
    "shit=np.dstack((test, new))\n",
    "\n",
    "# print shit\n",
    "\n",
    "print shit.shape\n",
    "for i in range(6):\n",
    "    print '.....................'\n",
    "    print  shit[:,:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=np.zeros(shape=[512,512,5])\n",
    "# print test.shape\n",
    "for i in range(5):\n",
    "    test[:,:,i].fill(i)\n",
    "np.delete(test, 1)\n",
    "new=np.zeros([512,512,1])\n",
    "new[:,:,0].fill(6)\n",
    "# print test[:,:]\n",
    "# print new\n",
    "\n",
    "print test.shape\n",
    "print new.shape\n",
    "\n",
    "shit=np.concatenate((test, new),axis=2)\n",
    "\n",
    "# print shit\n",
    "\n",
    "print shit.shape\n",
    "for i in range(6):\n",
    "    print '.....................'\n",
    "    print  shit[:,:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5# Comput \n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=np.array([[1,2,3],[1,2,3]])\n",
    "cover=np.array([[1,1,1],[1,1,0]])\n",
    "print test.shape\n",
    "print cover.shape\n",
    "\n",
    "shit=test*cover\n",
    "print shit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.zeros((2,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
