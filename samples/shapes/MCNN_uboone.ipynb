{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn.model import log\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "particle2pdg={11:'eminus',-11:'eminus',13:'muon',-13:'muon',22:'gamma',211:'piminus',-211:'piminus',2212:'proton'}\n",
    "pdg2instance={'eminus':3,'gamma':4,'muon':6,'piminus':8,'proton':9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from larcv import larcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ShapesConfig(Config):\n",
    "    \"\"\"Configuration for training on the toy shapes dataset.\n",
    "    Derives from the base Config class and overrides values specific\n",
    "    to the toy shapes dataset.\n",
    "    \"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"Particles\"\n",
    "\n",
    "    # Train on 1 GPU and 8 images per GPU. We can put multiple images on each\n",
    "    # GPU because the images are small. Batch size is 8 (GPUs * images/GPU).\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 2\n",
    "    \n",
    "    BACKBONE_STRIDES = [4, 8, 16, 32, 64, 128, 256]\n",
    "    \n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 8  # background + particles\n",
    "\n",
    "    # Use small images for faster training. Set the limits of the small side\n",
    "    # the large side, and that determines the image shape.\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "\n",
    "    # Use smaller anchors because our image and objects are small\n",
    "    RPN_ANCHOR_RATIOS = [0.5,  1,  2,  4,   8,  16, 32]\n",
    "    RPN_ANCHOR_SCALES = (8  , 16, 32, 64, 128, 256, 512)  # anchor side in pixels\n",
    "\n",
    "    # Reduce training ROIs per image because the images are small and have\n",
    "    # few objects. Aim to allow ROI sampling to pick 33% positive ROIs.\n",
    "    TRAIN_ROIS_PER_IMAGE = 32\n",
    "\n",
    "    # Use a small epoch since the data is simple\n",
    "    STEPS_PER_EPOCH = 100\n",
    "\n",
    "    # use small validation steps since the epoch is small\n",
    "    VALIDATION_STEPS = 5\n",
    "    \n",
    "    USE_MINI_MASK = False\n",
    "    \n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    \n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    \n",
    "#     IMAGE_CHANNEL_COUNT = 1\n",
    "    \n",
    "#     MEAN_PIXEL = [120]\n",
    "    \n",
    "#     IMAGE_SHAPE = [512,512,1]\n",
    "config = ShapesConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=8):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Change the default size attribute to control the size\n",
    "    of rendered images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRGBfromI(RGBint):\n",
    "#     print RGBint\n",
    "    RGBint=int(RGBint)\n",
    "    blue =  RGBint & 255\n",
    "    green = (RGBint >> 8) & 255\n",
    "    red =   (RGBint >> 16) & 255\n",
    "    return red, green, blue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ShapesDataset(utils.Dataset):\n",
    "    def __init__(self, input_file):\n",
    "        self.iom=larcv.IOManager(0) \n",
    "        self.iom.add_in_file(input_file)\n",
    "        self.iom.initialize()\n",
    "        super(ShapesDataset, self).__init__()\n",
    "    \n",
    "    def load_shapes(self, count, height, width):\n",
    "        # Add classes\n",
    "        self.add_class(\"Particles\", 1, 11)\n",
    "        self.add_class(\"Particles\", 2, -11)\n",
    "        self.add_class(\"Particles\", 3, 13)\n",
    "        self.add_class(\"Particles\", 4, -13)\n",
    "        self.add_class(\"Particles\", 5, 22)\n",
    "        self.add_class(\"Particles\", 6, 211)\n",
    "        self.add_class(\"Particles\", 7, -211)\n",
    "        self.add_class(\"Particles\", 8, 2212)\n",
    "\n",
    "        for i in range(count):\n",
    "            self.load_this_entry(i)\n",
    "            pdgs=[]\n",
    "                \n",
    "            for j, roi in enumerate(self.ev_roi.ROIArray()):\n",
    "                if j==0 : continue # First ROI name null with producer of iseg\n",
    "                if roi.PdgCode()==111: continue #pi_zero                                                                                   \n",
    "                if roi.PdgCode()==321: continue #Kplus                                                                                     \n",
    "                if roi.PdgCode()==1000010020: continue #Dutron...                                                                          \n",
    "                if roi.PdgCode()==1000010030: continue #Tritium...                                                                         \n",
    "                if roi.PdgCode()==1000010040: continue #Alpha...                                                                           \n",
    "                if roi.PdgCode()==1000020030: continue #Alpha...\n",
    "                if roi.PdgCode()==1000020040: continue #Alpha... \n",
    "                pdgs.append(roi.PdgCode())\n",
    "            self.add_image(\"Particles\", image_id=i, path=None,\n",
    "                           width=width, height=height,\n",
    "                           bg_color=0, pdgs=pdgs)\n",
    "    \n",
    "    def load_this_entry(self, entry):\n",
    "        self.iom.read_entry(entry)\n",
    "        self.ev_image    = self.iom.get_data(larcv.kProductImage2D,\"wire\")\n",
    "        self.ev_roi      = self.iom.get_data(larcv.kProductROI,\"iseg\")\n",
    "        self.ev_instance = self.iom.get_data(larcv.kProductImage2D,\"segment\")\n",
    "        self.plane=2\n",
    "        #print \"run\", ev_image.run(),\", subrun\", ev_image.subrun(), \", event\",ev_image.event()\n",
    "        #print ev_image.Image2DArray().size()\n",
    "        return self.ev_image.Image2DArray()[self.plane], self.ev_instance.Image2DArray()[self.plane],self.ev_roi.ROIArray()\n",
    "\n",
    "    \n",
    "    def load_image(self, image_id):\n",
    "        image,_,_ = self.load_this_entry(image_id)\n",
    "        img_np_=larcv.as_ndarray(image)\n",
    "#         print 'before thresholding, sum is ', np.sum(img_np_)\n",
    "        image.threshold(10,0) #thershold value here \n",
    "        img_np=larcv.as_ndarray(image)\n",
    "#         print 'after thresholding, sum is ', np.sum(img_np_)\n",
    "        img_np=img_np.reshape(512,512,1)\n",
    "        img_np3=np.repeat(img_np,3).reshape(512,512,3)\n",
    "        img_np3=np.round(img_np3,0)\n",
    "        return img_np3\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"Particles\":\n",
    "            return info[\"Particles\"]\n",
    "        else:\n",
    "            super(self.__class__).image_reference(self, image_id)\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        pdgs = info['pdgs']\n",
    "        count = len(pdgs)\n",
    "        mask = np.zeros([info['height'], info['width'], count], dtype=np.uint8)\n",
    "\n",
    "#         img = self.ev_instance.Image2DArray()[self.plane]\n",
    "        image,img_mask,_ = self.load_this_entry(image_id)\n",
    "        image.binary_threshold(0,0,1)\n",
    "        img_ori_np = larcv.as_ndarray(image)\n",
    "        #print 'img_ori_np shape', img_ori_np.shape\n",
    "        y = set(img_ori_np.flatten())\n",
    "        #print y\n",
    "        img_mask_np = larcv.as_ndarray(img_mask)\n",
    "        #print 'img_mask_np shape', img_mask_np.shape\n",
    "        for i,pdg in enumerate(pdgs):\n",
    "            instance = pdg2instance[particle2pdg[pdg]]\n",
    "            img_np_=img_mask_np.copy()\n",
    "            img_np_[img_np_!=instance]=0\n",
    "            img_np_[img_np_==instance]=1\n",
    "\n",
    "            img_np_=img_np_*img_ori_np\n",
    "            \n",
    "            img_np_=img_np_.reshape(512,512,1)\n",
    "            \n",
    "            mask[:,:,i:i+1]=img_np_\n",
    "            \n",
    "        occlusion = np.logical_not(mask[:, :, -1]).astype(np.uint8)\n",
    "        for i in range(count-2, -1, -1):\n",
    "            mask[:, :, i] = mask[:, :, i] * occlusion\n",
    "            occlusion = np.logical_and(occlusion, np.logical_not(mask[:, :, i]))\n",
    "        class_ids = np.array([self.class_names.index(s) for s in pdgs])\n",
    "        return mask, class_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_train = ShapesDataset(\"/data/dayajun/sw/Mask_RCNN/uboone/training_data/75_200.root\")\n",
    "dataset_train.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_train.prepare()\n",
    "\n",
    "dataset_val = ShapesDataset(\"/data/dayajun/toymodel/uboone/train_data/75_200_val.root\")\n",
    "dataset_val.load_shapes(50, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])\n",
    "dataset_val.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_ids = np.random.choice(dataset_train.image_ids, 4)\n",
    "image_ids=[0]\n",
    "for image_id in image_ids:\n",
    "    image = dataset_train.load_image(image_id)\n",
    "    mask, class_ids = dataset_train.load_mask(image_id)\n",
    "    print image_id\n",
    "    print image.shape\n",
    "    print mask.shape\n",
    "    for i in xrange(mask.shape[-1]):\n",
    "        print np.sum(mask[:,:,i]),\n",
    "    print ' '\n",
    "    print class_ids\n",
    "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Create model in training mode\n",
    "# model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "#                           model_dir=MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Training Heads\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE, \n",
    "#             epochs=1, \n",
    "#             layers='heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Training ALl\n",
    "# model.train(dataset_train, dataset_val, \n",
    "#             learning_rate=config.LEARNING_RATE / 10,\n",
    "#             epochs=2, \n",
    "#             layers=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class InferenceConfig(ShapesConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "inference_config = InferenceConfig()\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"inference\", \n",
    "                          config=inference_config,\n",
    "                          model_dir=MODEL_DIR)\n",
    "\n",
    "# Get path to saved weights\n",
    "# Either set a specific path or find last trained weights\n",
    "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\n",
    "# model_path = model.find_last()\n",
    "model_path=\"/data/dayajun/sw/Mask_RCNN/logs/particles20180920T1657/mask_rcnn_particles_0030.h5\"\n",
    "\n",
    "# Load trained weights\n",
    "print(\"Loading weights from \", model_path)\n",
    "model.load_weights(model_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Look at dataset_val\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "image_id = random.choice(dataset_val.image_ids)\n",
    "print image_id\n",
    "original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "    modellib.load_image_gt(dataset_val, inference_config, \n",
    "                           image_id, use_mini_mask=False)\n",
    "\n",
    "# for row in original_image:\n",
    "#     for column in row:\n",
    "#         if np.sum(column)>0 :print column\n",
    "    \n",
    "#     log(\"original_image\", original_image)\n",
    "#     log(\"image_meta\", image_meta)\n",
    "#     log(\"gt_class_id\", gt_class_id)\n",
    "#     log(\"gt_bbox\", gt_bbox)\n",
    "#     log(\"gt_mask\", gt_mask)\n",
    "#     print np.sum(original_image)\n",
    "\n",
    "#     print '===========Detection==========='\n",
    "\n",
    "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                            dataset_train.class_names, figsize=(8, 8),ax=ax0)\n",
    "\n",
    "results = model.detect([original_image], verbose=1)\n",
    "\n",
    "r = results[0]\n",
    "#     print r['rois'].shape\n",
    "#     print r['masks'].shape\n",
    "#     print r['class_ids'].shape\n",
    "#     print np.sum(original_image)\n",
    "\n",
    "print np.sum(r['masks'])\n",
    "\n",
    "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            dataset_val.class_names, r['scores'], ax=ax1)\n",
    "\n",
    "# visualize.display_differences(original_image,gt_bbox, gt_class_id, gt_mask, r['rois'],\\\n",
    "#                               r['class_ids'],r['scores'],r['masks']\\\n",
    "#                              ,dataset_train.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Look at trainset_data\n",
    "for image_id in xrange(0,20):\n",
    "    fig, (ax0,ax1) = plt.subplots(1,2,figsize=(16,8))\n",
    "\n",
    "    #image_id = random.choice(dataset_val.image_ids)\n",
    "    #print image_id\n",
    "    original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_train, inference_config, \n",
    "                               image_id, use_mini_mask=False)\n",
    "\n",
    "#     log(\"original_image\", original_image)\n",
    "#     log(\"image_meta\", image_meta)\n",
    "#     log(\"gt_class_id\", gt_class_id)\n",
    "#     log(\"gt_bbox\", gt_bbox)\n",
    "#     log(\"gt_mask\", gt_mask)\n",
    "#     print np.sum(original_image)\n",
    "\n",
    "#     print '===========Detection==========='\n",
    "\n",
    "    visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \n",
    "                                dataset_train.class_names, figsize=(8, 8),ax=ax0)\n",
    "\n",
    "    results = model.detect([original_image], verbose=1)\n",
    "\n",
    "    r = results[0]\n",
    "#     print r['rois'].shape\n",
    "#     print r['masks'].shape\n",
    "#     print r['class_ids'].shape\n",
    "#     print np.sum(original_image)\n",
    "\n",
    "    visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \n",
    "                                dataset_train.class_names, r['scores'], ax=ax1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute VOC-Style mAP @ IoU=0.5# Comput \n",
    "# Running on 10 images. Increase for better accuracy.\n",
    "image_ids = np.random.choice(dataset_val.image_ids, 10)\n",
    "APs = []\n",
    "for image_id in image_ids:\n",
    "    # Load image and ground truth data\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n",
    "        modellib.load_image_gt(dataset_val, inference_config,\n",
    "                               image_id, use_mini_mask=False)\n",
    "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\n",
    "    # Run object detection\n",
    "    results = model.detect([image], verbose=0)\n",
    "    r = results[0]\n",
    "    # Compute AP\n",
    "    AP, precisions, recalls, overlaps =\\\n",
    "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "    APs.append(AP)\n",
    "    \n",
    "print(\"mAP: \", np.mean(APs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test=np.array([[1,2,3],[1,2,3]])\n",
    "cover=np.array([[1,1,1],[1,1,0]])\n",
    "print test.shape\n",
    "print cover.shape\n",
    "\n",
    "shit=test*cover\n",
    "print shit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
